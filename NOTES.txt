--------------- DRAFT ------------

PURPOSE
-------
The purpose of this document is to describe, step by step, the 
implementation of PyNodes, particularly with respect to the 
Pythonic apporach we take to solving this problem.

We will start from first principles and build up.  By 
first principles I mean writing code from scratch to 
solve the following problem:

A functional-reactive, graph based language is based on 
a declarative model in which values and computations
are treated as nodes on a graph, and edges represent
data flows.

The functional-reactive piece comes into plan in that
instead of requiring a user to 'ask' for a value
and compute it then, we flip the model and instead
push updates from the input side, allowing the user
to directly change inputs and be alerted to results.

This is not a new concept: it's an event-based model,
with lazy computation and memoization.  Nothing
here requires advanced knowledge although we will 
use some lesser used Python features, such as metaclasses,
decorators, and contexts.  But even here, the ways in
which we use these are pretty standard and, as will be shown,
are a natural fallout of an interative approach to
developing the PyNodes code.

Enough preface: Let's move forward.

A PYTHON GRAPH 
--------------
Again, the first thing to note is that none of the concepts 
included herein are new; what I'm doing here is combining 
common function-oriented
programming techniques with a directed acyclic graph data structure
and some loose functional-reactive-like properties

The core concept is that of the graph:
  http://en.wikipedia.org/wiki/Directed_acyclic_graph

I've commented below the decisions I made and why I made them,
and have documented the code used, explaining the inspiration
and source.

On to the graph.

Any code, be it interpreted or compiled, results in a set
of machine instructions that can read input, write output,
or perform some calculation (which itself means generally
reading and # writing to a register or other source).

It's similar to a function in mathematics.  When I write
an equation like:
    
   y + z / q

I am implying a certain functional mapping between sets.

The functions here are something like:

   sum : R x R -> R
   div : R x R -> R

and, when realized in a linear computer domain, can
be applied only one at a time.  Hence we introduce precedence
rules that indicate diffentively when something executes,
time wise, relative to something else.

For example, in arthimetic the precedence rules indicate
that, without groupings, division has precedence over
addition.

Using these precedence rules and the functions above,
then, we can require the original equation as:

   sum(y, div(z,q))

Which can be represented as a tree that 'flows' upward.

    sum
   /   \
 y     div
      /   \
     z     q


In fact, there's nothing to prevent us from writing

   sum(div(y,z), div(z,q))

which, when visualized, becomes

       sum
      /   \ 
    div   div
   /   \ /   \
  y     z     q

which is not a tree, but rather a graph.

It takes no deep conceptual leap to realize that a
computer program is structured the same way.  Indeed, 
if I write:
  
 def sum(x, y):
     return x + y

 def div(x, y):
     return x / y

I can then run:

  y = 1
  z = 2
  q = 3
  sum(div(y,z), div(z,q))

and presto, I have the same result in code.  AND the graph
that would be generated is the same.

I can change values of y, z, and q and get corresponding
results.

So let's see: we have variables in which we have values that
act as INPUTS to our functions.  We have FUNCTIONS.  And
we have OUTPUTS to these functions that are fed up to 
other FUNCTIONS.

This is a graph, and we can implement a graph in Python
easily enough:

class Graph(object):
    def __init__(self, nodes, edges):
       self.nodes = nodes
       self.edges = edges

where nodes are either callables or non-callables, and edges is
a dictionary that maps a node to its input nodes, one-to-one
with its arguments, if it's a calculation.

For example, the graph representation of the equation above
would be

sum = lambda x,y: x + y
div1 = lambda x,y: x / y
div2 = lambda x,y: x / y
y = 1
z = 2
q = 3
graph = Graph([sum, div1, div2, y, z, q], {sum: [div1, div2], div1: [y,z], div2: [z,q]})

We now have everything we need to reconstruct the computation.  The code 
might look something like this:

    def computeNode(node):
        if not callable(node):
            return node
        return node(*[self.computeNode(n) for n in edges.get(node, [])])

The div1/div2 thing is a bit dumb but was necessary because we don't
have a distinct label to distinguish between the two ways it is called.

So let's add a new class:

class Node(object):
    def __init__(self, value):
        self.value = value

and change our Graph semantics: nodes is now a collection of
nodes, and edges maps a given node to its input nodes.

We still have our functions:

sum = lambda x,y: x + y
div = lambda x,y: x / y

But now we define div only once, and refer to it in a node.

The nodes are:

sumNode = Node(sum)
div1Node = Node(div)
div2Node = Node(div)
yNode = Node(y)
zNode = Node(z)
qNode = Node(q)

And the edges are:

{
    sumNode: [div1Node, div2Node],
    div1Node: [y, z],
    div2Node: [z, q]
}

And we can update computeNode accordingly.

So we've now represented the graph as an object, the nodes as
objects, but we still track the edges manually.  How might
we get rid of the need to do this?

Let's consider what the div1Node does.  It runs a computation
that, when represented as a function (not a lambda) looks like this:

def div(x, y):
    return x + y

Every time I want to compute new values for x and y in our
existing graph I need to update the edges; but really, the
relationships haven't changed, just the VALUES returned
by those relationships.

But another way, I am not changing the structure of the graph.
I am updating the graph in a structure-preserving way. So can
I decouple the value changes from the structure?

What would I need to do this?

Well, one way is to represent the graph itself as an object.
We can easily do this:

class MyGraph(object):

    def __init__(self, y, z, q):
        self.y, self.z, self.q = y, z, q

    def div1(self):
        return self.y / self.z

    def div2(self):
        return self.z / self.q

    def sum(self):
        return self.div1() + self.div2()

OK, what have we done?  We've seen that have two types of nodes:
those that compute values and those that are essential set to 
a value; regular ol' programming practice.

But now we've made our graph less general by hard-coding the 
names of our input nodes, and representing the computation
nodes as functions.

Now if I want to change my computation I just update the
inputs.  For example:

   graph = MyGraph(10, 5, 1)
   graph.sum()                -> 3
   graph.z = 10
   graph.sum()                -> 2

and so forth.

So this is a nice graph, but how might I make it even better?

Well, what if we introduce a couple new computations:

    def expensive(self):
        someThingExpensive(self.div1(), self.div2())

    def cheap(self):
        return somethingCheap(self.someThingExpensive())

 The idea here is that the "cheap" function is used a lot and
 is intended to be fast.  But perhaps it needs a value that
 is very expensive to compute but once computed doesn't
 need to be updated often.

 The logical thing to do is to cache the expensive value.
 So perhaps we implement cheap as so:

    def cheap(self):
        if not self.expensiveValue:
            self.expensiveValue = self.someThingExpensive()
        return somethingCheap(self.expensiveValue)

 Now we only calculate expensive value once.  After that we
 have its value cached, and the future computations of
 cheap are very easy.

 There is actually another way to do this that typically
 works on the function level and requires that the function
 value is wholly determined by the arguments to that function.
 It's called memoization, and the idea is that given a 
 function:

   def f(*args):
       return ...

 and assuming the function is written in a way such that
 the value returned by it is fully computed from and
 always a function of *args, when we wrap this function
 with a cache that stores that value, and the next time
 a call to f is made with the same arguments we just
 return the cached value.

 Let's write a function that does this.

   memoizedValues = {}
   def memoize(f, *args):
       key = (f,) + args
       if key not in memoizedValues:
           memoizedValues[key] = f(*args)
       return memoizedValues[key]

We can then use this function by wrapping any call we want
memoized with it:

  def div(x,y):
      return x / y

Now normally if I call this function the function body 
will run at every execution.

z = div(10,2)             -> Executes div
z = div(10,2)             -> Executes div

So in the above example, div actually executed twice.

But let's run it with out memoizer:

z = memoize(div, 10, 2)   -> Executes div
z = memoize(div, 10, 2)   -> Does NOT execute div; returns cached value

We've just saved some computational power!

But this is not very Pythonic.  Having to wrap every call to memoize 
is cumbersome.  

In fact, we can generalize this: while we have -wrapped- the call
to our function with the caching ability, we haven't actually
modified what the function itself does.

Luckily, this pattern is so common that Python provides a feature 
intended to address it called a "decorator."

A decorator is a function that wraps another function but allows
the user to continue to use the original function under its
same name.

A decorator's job is to accept a function and return a wrapped
version of that function.

Let's update memoize to do this:

   memoizedValues = {}
   def memoize(f):
       def wrapped(*args):
           key = (f,) + args
           if key not in memoizedValues:
               memoizedValues[key] = f(*args)
           return memoizedValues[key]
       return wrapped


We can now decorate our original function during its 
declaration:

@memoize
def div(x, y):
    return x / y

and now use it as it would typically be used:

div(10,2)             -> Executes div
div(10,2)             -> Does not execute div
div(10,1)             -> Executes div (because we've changed the arguments)
div(10,1)             -> Does not execute div

So now we have a Pythonic way to cache computed values as 
long as the functions we memoize are pure.  (Pure is a concept
from mathematics; a function is pure if for given inputs
it always returns the same output, and that it never has
a 'side-effect' (or alters the state of the world).
Without both we cannot reliably memoize a function because
even if the value returned is the same, it may be modifying
some state as a side-effect that won't be modified if
the next time we call the function we don't actually run
it but rather return its cached vlaue.  We'll come back 
to this topic later.

Back to the expensive calculation.  Excellent!  Now
we can just memoize it and be done, right?

    @memoize
    def expensive(self):
        someThingExpensive(self.div1(), self.div2())

    def cheap(self):
        return somethingCheap(self.someThingExpensive())


I run cheap, it computes expensive the first time, but as
a result of the memoization future computations are
avoided.  Awesome.

EXCEPT.  We forgot one minor detail.  Our memoization
function assumes the inputs to the function it 
memoizes are all arguments to that function.  But
we are representing our computation as a graph, and
in our graph all the inputs are leaf nodes!  

That is, expensive evaluates the div1 and div2 nodes,
and these nodes use y, z, and q.  If I change y, z, and 
q, then, the result of div1/div2 might change, and hence
the result of expensive might change.

But we're not doing to see this change because from
the memoizing function's perspective the inputs are
always the same: a single variable 'self'!

So the question is this: can we maintain our
graph model (avoiding the need to pass parameters 
into every call) but also somehow memoize the values?

There is a way.  It involves some thinking, but is
rather basic and can be implemented with standard
Python idioms.

What do we know?

  We know that expensive uses div1 and div2.
  We know that div1 depends on y and z.
  We know that div2 depends on z and q.
  We know that the values to y, z, and q are input
     nodes.
  We know that div1's value may change if y or z changes.
  We know that div2's value may change if z or q changes.
  We know that expensive's value may change if div1 or div2
     changes, and thus that its value may change if the
     things that cause div1 and div2 to change change.
  We know that expensive is an expensive computation.
  We know we want to cache expensive.
  We know that reliably caching expensive means knowing
     when its inputs change.
  We know its inputs aren't specified as arguments,
     but are indirectly captured as function calls
     in expensive's method body.
 
What do we need?

 To memoize expensive, then, we need a means of knowing
 (or somehow 'alerting') the memoizing function to
 the fact that is inputs have changed, and we need a
 way of recording those inputs outside of using an 
 argument list.

Let's figure this out.

One way to do it is pass parameters to memoize that
indicate which things expensive depends on.  We might
try that.

We redefine memoize as follows:

def memoize(f, dependencies=[]):
   args = []
   for dependency in dependencies:
       if not callable(dependency):
           args.append(dependency)
       args.append(dependency())
   key = (f,) + args
   if key not in memoizedValues:
       memoizedValues[key] = f()
   return memoizedValues[key]

We can now decorate expensive as follows:

@memoize([div1, div2])
def expensive(self): 
   ...

So what happens now when we run expensive?

The first time it runs, we call div1() and we call div2(), which in
turn use y, z, and q, and get the values.  These become
the new 'args' to expensive (which we know because expensive
makes the same calls to these functions in its method body).

We then create a key from these values, check whether a memoized
value is present and, if not, we call f() to compute it.

Note that f() is not called with arguments as it was before.
It doesn't accept arguments!  We just now we need to call 
it because we precomputed the values that would be returned
by the things it does call.  The end result is the same,
though, we now have a nicely memoized value.

Oooh by this sucks.  In a number of ways:

First, we now have to call the methods expensive uses
every time, even if we don't end up calling expensive
itself.  We -always- call div1 and div2 in this case.
We haven't saved us computation time there.

Second, we have duplicated business logic already present
in the body of the expensive method into a new place.
If expensive requires use of a new method, div3,
then we need to both update the method body to use
it -and- update the decorator to reflect this as well.
Storing business logic in two places is the ultimate 
anti-pattern.

Finally, we still don't really know we 'depend' on 
y, z, or q, which is useful information.  We can
only know this is div1 and div2 are also memoized.
This actually makes sense, and we'll see why soon,
but we still run into two issues above, but now
everywhere.

We need a better way.

To simplify things, let's move from this graph
to an even simpler one:

class MyGraph2(object):
   def __init__(self, x):
       self.x = x

   def compute(self):
       return self.x

and let's assume we want to memoize the compute function.
We've narrowed the problem a bit, as now we are dealing
with the input nodes directly, and in fact just one 
input node.

So using our prior example I can decorate compute with
the following:

   @memoize([x])
   def compute(self):
       return self.x

This doesn't, though, get around any our issues
before, but clarifies one goal.  How can I avoid
having to pass [x] in to memoize; it's already 
implicitly an input in the method body.

Consider why we pass x in to begin with, and what
we're capturing.

(1) We've capturing x's value each time compute()
    is run.  

(2) We've indicating that compute depends on x,
    which as I already said is redundant.

Let's look at each of these of these in turn and
ask, is there a way to avoid evaluating the graph
or representing it twice that still allows us
to memoize?

Consider capturing x's value.  Let's assume for 
simplicitly that our memoize function only
ever stores the most recent computation only
until that computation is no longer valid.
This allows us to rephrase the question from
"have we seen this input before?" to "has the input
changed since the last time we computed the value?"

Let's assume memoize stores this as an indicator
in its function body.  I'm also going to write
some pesudocode that demonstrates what we want to
do more generally.  We'll then flesh it out.

Our new memoize now wants to know if any
of its dependencies changed.

currentDeps = {}
memoizedValue = None
def memoize(f, dependencies=[]):
   hasChanged = f not in currentDeps
   while not hasChanged:
       for dependency in dependencies:
           v = dependency() if callable(dependency) else dependency
           if v != currentDeps[dependency]:
               hasChanged = True
   if hasChanged:
       memoizedValue = f()
   return memoizedValue
   
This hasn't really fixed any of our problems, though,
as we still need to maintain the dependencies outside
the graph, as well as evaluate their values to check 
whether they have changed.

But we do now have this notion of 'hasChanged' - and
we know that memoize depends on some set of things.

So let's look at the other side in our example.
What does it mean to have changed x?  In this case
that is simple: x changes if we have set it to a 
new value.

The next question is obvious: is there a way
such that when we change x to a new value, x 
can just tell the memoized functions that
depend on it they need to recompute?  x knows
it has changed, we shouldn't have to have 
every memoized function that uses it track 
whether this is true or not by evaluating x
and storing its old value.

But we can't just have 'hasChanged' on x,
because we can never be sure it will be set
back to False.  We can't basically.  This is
not a boolean we can store for x.  It's
a boolean we need to store for each thing
that uses x, because only after all of them
have recomputed based on x's new value would
it be safe to say x has no longer changed.

Luckily there is already a very common
way of handing this type of thing known
as a callback.  Instead of asking x
for its value each time we make a call
that uses it, and incurring the additional
overhead, our memoize function could
supply x with a means of informing it
when it changes.

This is the subscriber pattern and is widely 
used.  Essentially we want to do this:

For each memoized function provide a callback
to the subscribed dependency, and modify 
our code such that on any change to the dependency
the call back is executed.

Also, instead of using the name 'hasChanged'
we will just indicate whether the memoized
function's value is still valid or not.
It really doesn't matter which input changed:
if just one changed the memoized value needs to be 
recomputed.

Let's give this a shot.  Here's some pseudocode,
but keep in mind we'll need to rewrite this as a
stateful object in our real implementation.

valid = False
def memoize(f, deps=[]):
    def changed(node):
        valid = False
    for d in deps:
        d.registerCallback(changed)
    def wrapped():
        if not valid:
            return f()
    return wrapped

The idea is when we decorate a function we register
a callback with the dependencies, the idea being that
these dependendency then execute the callback
when they are changed.

Except, of course, registerCallback doesn't exist.
Before we had a Node class in which we could have put
it, then we returned to regular variables.
Is there a way to merge these two concepts?

There are indeed a couple of ways.  We can use a
decorator here as well. Or we can use a metaclass
which is an even cleaner solution.  But let's start
with a decorator.

First we need to define our Node class again, but
now add the subscription stuff.

class Node(object):
   def __init__(self, value):
       self.value = value
       self.callbacks = set()

   def registerCallback(self, callback):
       self.callbacks.add(callback)

   def onChange(self):
       for callback in self.callbacks:
           callback(self)

The idea here is simple; we collect all the callbacks 
that have been registered with us into a set,
and introduce a method that executes these callbacks
(passing in the node as a sole argument to each).

We know we want to execute the callbacks when the
node changes, so we'll just call the driving function
'onChange'. 

Now let's update our class to wrap our input node
as a Node object:

class MyGraph2(object):
   def __init__(self, x):
       self.x = Node(x)
   
   @memoize([x])
   def compute(self):
       return self.x

Now this obviously captures the idea, but there
is still a problem. As a user I want to change the
value of x, but I don't care about the internal
representation.  That is, I want to run:

graph = MyGraph2(1)
graph.compute()           -> 1
graph.x = 20
graph.compute()           -> 10

and so forth.

But if I run

graph.x = 20

then graph.x is no longer a Node (which was created in __init__)
but is now, instead, an integer 20.  We need a way to force
the assignment to x to be wrapped in a Node.

As with many things in Python, there are a lot of ways to do this.
The most obvious approach is to use what is called a Python
property.  A property allows us to add some addaitional functionality
to the getting, setting, or deleting of a value.

So let's add a property to our MyGraph2 class for x.  One fallout
here is that we need to change the actual variable name to something
else, so where we used x before we'll now use _x.  As in self._x = Node(x).

Here's the property:

   @property
   def x(self):
       return self._x

   @x.setter
   def x(self, value):
       self._x.value = value
      
And of course we can now add the invalidation piece right in the
setter.

   @x.setter
   def x(self, value):
       self._x.value = value
       self._x.onChange()
   
  
Now we've accomplished what we want to accomplish! As least
for non-callable variables.  What about the methods themselves?
We want these to be nodes, too, so that they, too can be
subscribed to.

How might we do this?

One approach is to add code to our graph that wraps all the 
methods with Node calls.

Something like this:
    def __init__(self, x):
        self._x = x
        for k,v in dict(self):
            if callable(v):
               setattr(k, Node(v))

We also need to modify Node so that it can be "called" (because
now the compute method is a Node, which at present can't be
called.

So we'll add another function to Node:

    def __call__(self, *args):
        if not callable(self.value):
            raise RuntimeError("This isn't a callable Node.")
        return self.value(*args)

And things work as expected.

Note, though, that I added a callable test to the __call__ function
to make sure the value is a callable, and not a setting. 

So we have more-or-less eliminated the input update issue, even
though we're still tracking dependencies twice.  We've also
introduced quite a lot of overhead that the user would need to
take care of to use our model:

   A property for every input variable, which amounts to two functions.
   A decorator for every memorized function, which duplicates dependencies.
   Logic in __init__ that must be called to keep all of this together.
   Treatment of input nodes and calculation nodes in different ways.

And of course in this implementation we don't differentiate between
functions "on the graph" and others we may just want for non-graph
purposes (the most obvious being __init__, and in fact, the code
above wraps __init__ too, which is most certainly wrong).

So we've made progress, but there is still quite a bit we could
do to streamline things.  

For one, can we generalize the concept of a Node so that 
we don't need to treat input values and functions separately?

Second, can we get rid of all the overhead of these decorators
getters and setters, or at least in some way add them 
automatically.  Rule of thumb: whenever you find yourself
doing the same thing over and over there's probably a way to
generalize it. 

So our next step is to address these two issues.  But first
let's review what our code would look like on the original
MyGraph class we created above.
       

AN ASIDE:

When we represent computations as vertexes (or nodes) on 
graph, where inputs to the functions are treated as incoming edges and
and outputs as outgoing edges, we end up with what is essentially
a basis for graph programming, a means of programming well documented
in the literature (e.g., see http://reference.wolfram.com/mathematica\
/guide/GraphProgramming.html).

Perhaps most important is that with this model we gain the ability
to automatically determine when a node on the graph needs to change,
namely, when one of its inputs changes.  Of course this implies
that at least some of the input nodes can be changed by the the user,
and thus we have the notion of un-Settable nodes (the default),
and Settable nodes.  Settable nodes can be directly set by a
user.  For convenience we also allow Settable nodes to compute
their default values if they are not specifically set.

In terms of lazy evaluation, memoization, and other graph
concepts, these too are not new ideas and a Google search will
present plenty of examples.

I take the model one step further my introducing another
commonly known feature, an idea inspired by Photoshop.
In Photoshop one can work with layers of content, and higher
layers basically 'hide' what is visible in lower layers.
Well, it is trivial to see that this same concept can easily
be applied to a graph.  Wherever you have node with a certain
value, you can layer on top of it another value, just as in
Photoshop.  But "hiding" that old value here also means 
making sure that anything that depended upon it also
reflects the new value as long as you're working in that layer.

These concepts are so obvious and so well known that I've
decided to call them exactly what they are: graphs, nodes,
and layers.  We'll see terminology frequently below.

Any computer science major knows what a graph is,
and knows how to represent it as a data structure: even
something simple as a value, a set of edges going out,
and a set of edges coming in.  This is close to the set
theoretical definition, in fact.

So if were to write a graph we could easily do so in Python
by creating classes to refer to all of these pieces. And that's
what we do below.  But in addition, to make things just a little
easier for a user, we provide some extra glue.  We allow users
to decorate their Python object methods such that, behind the
scenes, these methods are treated as Python nodes.  Again,
none of these concepts is new or special: decorators are the 
standard practice for this type of thing, and metaclasses,
which we leverage to provide some basic sanity checks, have
been used in all kinds of creative ways for exactly this type of
abstraction.

So in the end, we are writing what is really basic Python code,
combining common ideas and adding some additional features
others do not: such as the ability to track our node
dependencies at runtime.  We also add some obvious patterns
that apply to the graph, such as the visitor pattern, as well
as some helpers to assist in creating new objects.  But any
beginning Python user could introduce these himself as well,
and I hope that some enterprising folks do contribute to 
the project.

